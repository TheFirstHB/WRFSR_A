{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb707508-4422-44ab-baf1-f117b4d8672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#前提ライブラリ\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "#torch関連\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformers import CLIPVisionConfig\n",
    "\n",
    "#作成したモデルのインポート\n",
    "from models.Denoisingmodel import DenoisingModel\n",
    "from models.Diffusionmodel import Diffuser\n",
    "\n",
    "#その他\n",
    "import math\n",
    "import datetime\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1aee5-f6b8-4956-b5c5-641e4447bd15",
   "metadata": {},
   "source": [
    "# 学習条件の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a179af08-96c1-4174-9197-0ad7c5581ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "条件設定\n",
    "シード固定\n",
    "'''\n",
    "\n",
    "\n",
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "\n",
    "    image_size = 64 \n",
    "    train_batch_size = 32\n",
    "    \n",
    "\n",
    "    num_epochs = 20\n",
    "\n",
    "    num_timesteps = 1000\n",
    "    \n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "\n",
    "    save_model_epochs = 50\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    clipconf = CLIPVisionConfig(\n",
    "        projection_dim = 512,\n",
    "        num_channels = 1,\n",
    "        image_size = 64\n",
    "        )\n",
    "\n",
    "config = TrainingConfig()\n",
    "torch_fix_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c78f9a-7bf1-4e51-84b7-281d5fa769b4",
   "metadata": {},
   "source": [
    "# データセットの準備\n",
    "データはwrf&meshagr.ipynbで整形\n",
    "\n",
    "訓練:テスト=8:2に分割\n",
    "\n",
    "時系列をランダムにシャッフル、Zスコア標準化を行った。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ee014-8874-48cd-9296-b06714b1407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "年別データ結合\n",
    "'''\n",
    "\n",
    "def make_tensor(data='TMP',area='manji',years=[2021,2022,2023],source='/mnt/nadaru/trainingdataset'):\n",
    "    dss = []\n",
    "    for y in years:\n",
    "        filename = f\"{data}_{y}_{area}.nc\"\n",
    "        filepath = os.path.join(source,filename)\n",
    "        try:\n",
    "            d = xr.load_dataset(filepath)\n",
    "            dss.append(d)\n",
    "            print(filename)\n",
    "        except:\n",
    "            pass\n",
    "    ds = xr.concat(dss,dim=\"t\")\n",
    "    if np.sum(np.isnan(ds['amgsd'].values)) != 0:\n",
    "        print('Warning:nan detected')\n",
    "        ds.dropna(dim='y',how='any')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3512df63-4618-407a-9678-bbc99eb8210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "データセット取得\n",
    "訓練:テスト=8:2(シャッフル)\n",
    "標準化\n",
    "'''\n",
    "img_size = config.image_size\n",
    "batch = config.train_batch_size\n",
    "epochs = config.num_epochs\n",
    "lr_rate = config.learning_rate\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#データセットの取得\n",
    "print('dataset loading三( ﾟ∀ﾟ)...')\n",
    "ds = make_tensor()\n",
    "\n",
    "lr = ds['WRF_1km'].values\n",
    "hr = ds['WRF_300m'].values\n",
    "amgsd = ds['amgsd'].values\n",
    "timeline = ds['WRF_300m'].t\n",
    "timecode = np.arange(len(timeline))\n",
    "\n",
    "hr_mean= hr.mean()\n",
    "hr_std = hr.std()\n",
    "\n",
    "print('dataset to tensor(jstammt)...')\n",
    "lr_tensor = torch.tensor(lr.astype('float'),dtype=torch.float32)\n",
    "hr_tensor = torch.tensor(hr.astype('float'),dtype=torch.float32)\n",
    "timecode_tensor =  torch.tensor(timecode.astype('float'))\n",
    "amgsd_tensor = torch.tensor(amgsd.astype('float'))\n",
    "\n",
    "\n",
    "trans = torchvision.transforms.Compose([\n",
    "                                        torchvision.transforms.Resize(size=(64, 64)),\n",
    "                                        torchvision.transforms.Normalize((hr_mean), (hr_std))])\n",
    "\n",
    "class WRFdatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, LR, HR, amd, timeline, transform = None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.lr = LR.unsqueeze(1)\n",
    "        self.hr = HR.unsqueeze(1)\n",
    "\n",
    "        self.time = timeline.to(torch.int)\n",
    "        self.amd  = amd.unsqueeze(1)\n",
    "        \n",
    "        self.datanum = len(timeline)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_lr = self.lr[idx]\n",
    "        out_hr = self.hr[idx]\n",
    "\n",
    "        out_amd = self.amd[idx]\n",
    "        out_time = self.time[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            out_lr = self.transform(out_lr)\n",
    "            out_hr = self.transform(out_hr)\n",
    "            out_amd = self.transform(out_amd)\n",
    "            \n",
    "\n",
    "        return out_lr, out_hr, out_amd, out_time\n",
    "\n",
    "print('dataset making...')\n",
    "dataset = WRFdatasets(lr_tensor, hr_tensor, amgsd_tensor, timecode_tensor, transform=trans)\n",
    "\n",
    "# 学習データ、検証データに 8:2 の割合で分割する。\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size]\n",
    ")\n",
    "print('kansei')\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch, shuffle = True, num_workers = 2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size = batch, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e3f1a-0d9d-41de-8e1e-74d688071454",
   "metadata": {},
   "source": [
    "# ノイズ除去モデルの学習\n",
    "ノイズ除去モデル：UNet2DConditionModel(Diffusers)\n",
    "\n",
    "損失関数：mseLoss\n",
    "\n",
    "最適化関数：AdamW\n",
    "\n",
    "GPU：nvidia RTX 3080 Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6e1a4-815e-4396-84db-407887528bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル呼び出し\n",
    "model = DenoisingModel(config)\n",
    "\n",
    "num_timesteps = config.num_timesteps\n",
    "diffuser = Diffuser(config.num_timesteps, device=device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "#学習\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss_sum = 0.0\n",
    "    cnt = 0\n",
    "    \n",
    "    for low, high, amd, time in tqdm(trainloader):\n",
    "        \n",
    "        #時系列エンコード\n",
    "        #dates = pd.to_datetime(timeline[time].values)\n",
    "        #dates_encoded = datetime_embedder(dates).unsqueeze(1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        low = low.to(device)\n",
    "        high = high.to(device)\n",
    "        t = torch.randint(1, config.num_timesteps+1, (len(high),), device=device)\n",
    "\n",
    "        x_noisy, noise = diffuser.add_noise(high,t) #画像にノイズ付加\n",
    "        noise_pred = model(t, x_noisy, low)\n",
    "        loss = F.mse_loss(noise, noise_pred)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        cnt += 1\n",
    "    print('loss:{:.4f}'.format(loss_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c82dc-03b0-4514-b326-89d7de655cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習後パラメータ保存\n",
    "dt = datetime.datetime.today()\n",
    "torch.save(model.state_dict(), f'saved_model/TMP_model_{str(dt.date)}.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
